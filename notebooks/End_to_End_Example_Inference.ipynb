{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92111249",
   "metadata": {},
   "source": [
    "# End to End Inference Tutorial\n",
    "Here we implement a complete end-to-end use of paltas. This notebook is intended as a 'minimal reproducible example', and thus doesn't use the full extent of the package, but should be a useful starting point. \\\n",
    "A number of the code-blocks simply run command-line instructions. This is intentional, as paltas is designed to run in the command-line. Furthermore, running such command-line statements allows easier transfer to remote computing clusters/parallelisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50353929",
   "metadata": {},
   "source": [
    "# Goals\n",
    "\n",
    "1. To be able to implement a simple end-to-end example of Paltas\n",
    "2. To understand how each of the packages inter-communicate, and which packages need to be run (and when), to perform hierarchichal inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2f3a6c-5fb2-41de-8c0a-02004fa5e3da",
   "metadata": {},
   "source": [
    "# Import Packages\n",
    "Here we import the required packages and define the training and model directories (where the training images and model weights are stored, respectively).\\\n",
    "The '/home/runner/work' referred to here is required to run this notebook as a Github Action, but should be changed to a prefered directory when running this notebook locally.\\\n",
    "Although tensorflow and emcee do not form part of the requirements for paltas, they are required for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16173c23-7349-4a92-b77b-a3137d750555",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T00:30:59.016982Z",
     "start_time": "2023-08-21T00:30:59.008566Z"
    }
   },
   "outputs": [],
   "source": [
    "paltas_directory = './'\n",
    "training_directory = '/home/runner/work/notebooks/End_to_End_Tutorial_Files/'\n",
    "model_directory = '/home/runner/work/notebooks/End_to_End_Tutorial_Files/'\n",
    "import os\n",
    "os.chdir(paltas_directory)\n",
    "from paltas.Analysis import hierarchical_inference,dataset_generation, loss_functions, conv_models\n",
    "from IPython.display import display,Pretty\n",
    "import matplotlib.pyplot as pl\n",
    "from scipy.stats import norm\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import corner\n",
    "import emcee\n",
    "import numba\n",
    "import h5py\n",
    "import glob\n",
    "import sys\n",
    "random_seed = 4\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5059aa-ca43-4cc6-b846-0d12d189b87e",
   "metadata": {},
   "source": [
    "# Generate Images\n",
    "We start by generating lensed images divided into training and validation sets. The images are saved within one\n",
    "h5 file for each run of generate.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d5184-2a2b-4fdc-a8e0-660b3996f105",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T16:51:11.772142Z",
     "start_time": "2023-08-07T16:50:01.191Z"
    }
   },
   "outputs": [],
   "source": [
    "!python3 ./paltas/generate.py ./paltas/Configs/Examples/config_simple_tutorial.py /$training_directory/training/1 --n 1000 --tf_record --h5\n",
    "!python3 ./paltas/generate.py ./paltas/Configs/Examples/config_simple_tutorial.py /$training_directory/validation/1 --n 1000 --tf_record --h5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65ab7d0-2334-4cb7-9e77-a8f656950667",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "The neural network is then trained. The --h5 indicates that the images were originally saved as h5 files, and\n",
    "should be retrieved as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77c2039a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# Includes a PEMD deflector with external shear, and Sersic sources. Includes \n",
       "# a simple observational effect model that roughly matches HST effects for\n",
       "# Wide Field Camera 3 (WFC3) IR channel with the F160W filter.\n",
       "\n",
       "import numpy as np\n",
       "from scipy.stats import norm, truncnorm, uniform\n",
       "paltas_directory = '/Users/hollowayp/paltas/'\n",
       "import os\n",
       "os.chdir(paltas_directory)\n",
       "#import sys\n",
       "#sys.path.append(paltas_directory)\n",
       "from paltas.MainDeflector.simple_deflectors import PEMDShear\n",
       "from paltas.Sources.sersic import SingleSersicSource\n",
       "from paltas.Substructure.subhalos_dg19 import SubhalosDG19\n",
       "\n",
       "# Define the numerics kwargs.\n",
       "kwargs_numerics = {'supersampling_factor':1}\n",
       "\n",
       "# This is always the number of pixels for the CCD. If drizzle is used, the\n",
       "# final image will be larger.\n",
       "numpix = 60\n",
       "\n",
       "# Define some general image kwargs for the dataset\n",
       "mask_radius = 0#0.5\n",
       "mag_cut = 3.0\n",
       "\n",
       "# Define arguments that will be used multiple times\n",
       "output_ab_zeropoint = 25\n",
       "\n",
       "config_dict = {\n",
       "\t'main_deflector':{\n",
       "\t\t'class': PEMDShear,\n",
       "\t\t'parameters':{\n",
       "\t\t\t'M200': 1e13,\n",
       "\t\t\t'z_lens': 0.5,\n",
       "\t\t\t'gamma': truncnorm(-20,np.inf,loc=2.0,scale=0.1).rvs,\n",
       "\t\t\t'theta_E': truncnorm(-1.1/0.15,np.inf,loc=1.1,scale=0.15).rvs,\n",
       "\t\t\t'e1': norm(loc=0.0,scale=0.1).rvs,\n",
       "\t\t\t'e2': norm(loc=0.0,scale=0.1).rvs,\n",
       "\t\t\t'center_x': norm(loc=0.0,scale=0.16).rvs,\n",
       "\t\t\t'center_y': norm(loc=0.0,scale=0.16).rvs,\n",
       "\t\t\t'gamma1': norm(loc=0.0,scale=0.05).rvs,\n",
       "\t\t\t'gamma2': norm(loc=0.0,scale=0.05).rvs,\n",
       "\t\t\t'ra_0':0.0, 'dec_0':0.0\n",
       "\t\t}\n",
       "\t},\n",
       "\t'source':{\n",
       "\t\t'class': SingleSersicSource,\n",
       "\t\t'parameters':{\n",
       "\t\t\t'z_source':truncnorm(-5,np.inf,loc=2.,scale=0.4).rvs,\n",
       "\t\t\t'magnitude':uniform(loc=-26,scale=5).rvs, #WHY DO THE MAGNITUDES NEED TO BE NEGATIVE, and why is -20 fainter than -26?\n",
       "\t\t\t'output_ab_zeropoint':output_ab_zeropoint,\n",
       "\t\t\t'R_sersic':truncnorm(-2,2,loc=0.35,scale=0.05).rvs,\n",
       "\t\t\t'n_sersic':truncnorm(-6.,np.inf,loc=3.,scale=0.5).rvs,\n",
       "\t\t\t'e1':norm(loc=0.0,scale=0.1).rvs,\n",
       "\t\t\t'e2':norm(loc=0.0,scale=0.1).rvs,\n",
       "\t\t\t'center_x':norm(loc=0.0,scale=0.16).rvs,\n",
       "\t\t\t'center_y':norm(loc=0.0,scale=0.16).rvs}\n",
       "\t},\n",
       "\t'cosmology':{\n",
       "\t\t'parameters':{\n",
       "\t\t\t'cosmology_name': 'planck18'\n",
       "\t\t}\n",
       "\t},\n",
       "\t'psf':{\n",
       "\t\t'parameters':{\n",
       "\t\t\t'psf_type':'GAUSSIAN',\n",
       "\t\t\t'fwhm': 0.67 #Using value from https://www.lsst.org/scientists/keynumbers\n",
       "\t\t}\n",
       "\t},\n",
       "#From Lenspop: https://github.com/tcollett/LensPop/blob/master/Surveys.py\n",
       "#self.pixelsize=0.18\n",
       "#self.side=111\n",
       "#self.bands=['g','r','i']\n",
       "#self.zeropoints=[30,30,30]\n",
       "#self.zeroexposuretime=25\n",
       "#self.skybrightnesses=[21.7,20.7,20.1]\n",
       "#self.exposuretimes=[3000,6000,6000]\n",
       "#self.gains=[4.5,4.5,4.5]\n",
       "#self.seeing=[.4,.4,.4]\n",
       "#self.nexposures=100\n",
       "#self.degrees_of_survey=18000\n",
       "#self.readnoise=(10/4.5)\n",
       "\t'detector':{\n",
       "\t\t'parameters':{\n",
       "\t\t\t'pixel_scale':0.18,'ccd_gain':4.5,'read_noise':10/4.5,\n",
       "\t\t\t'magnitude_zero_point':output_ab_zeropoint,\n",
       "\t\t\t'exposure_time':6000,'sky_brightness':20.1,\n",
       "\t\t\t'num_exposures':100,'background_noise':None\n",
       "\t\t}\n",
       "\t}\n",
       "}\n",
       "###^^ Currently modelling in i-band (i.e. using exposure time, sky_brightness specific to i-band, according to Collett 2015 values).\n",
       "###^^ Haven't yet included any background noise."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Pretty(\"./paltas/Configs/Examples/config_simple_tutorial.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db128f92-4fa7-4a30-9f0d-ccfa873e3705",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python3 ./paltas/Analysis/train_model.py ./paltas/Analysis/AnalysisConfigs/train_config_examp_tutorial.py --h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab7275b-80e1-40d3-84ea-21c0030062ec",
   "metadata": {},
   "source": [
    "# Generate Model Predictions\n",
    "Having trained the model, we locate the filename of the final epoch (this can be hardcoded instead if desired)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb92a00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T01:19:56.132009Z",
     "start_time": "2023-08-21T01:19:56.091308Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_weights_list(directory):\n",
    "    \"\"\" Function to return a list of weights filenames from the network\n",
    "    args: Directory containing the training, validation and weights files \"\"\"\n",
    "    weights_list = glob.glob(f'{directory}/model_weights/*')\n",
    "    weights_list = [elem.split('model_weights/')[1] for elem in weights_list]\n",
    "    return weights_list\n",
    "\n",
    "def return_final_epoch_weights(directory):\n",
    "    \"\"\" File to return the weight filename of the final trained epoch\n",
    "    args: Directory containing the training, validation and weights files \"\"\"\n",
    "    weights_list = load_model_weights_list(directory)\n",
    "    print(weights_list)\n",
    "    final_epoch =  np.max([int(elem.split('-')[0]) for elem in weights_list])\n",
    "    w_filename = [x for x in weights_list if x.startswith(\"{:02d}\".format(final_epoch)+'-')][0]\n",
    "    print('FINAL EPOCH',w_filename)\n",
    "    return directory+'/model_weights/'+w_filename\n",
    "\n",
    "final_weights_filename = return_final_epoch_weights(model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69745512-b912-4e77-b50d-ef31ab3d3a7f",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "The trained model is loaded (along with the network weights from the final epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e4b3b0-0cad-498e-b9e4-f3654f595592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T02:36:01.421110Z",
     "start_time": "2023-08-19T02:35:58.396547Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model_weights_filename,loss_type,model_type,learning_params,log_learning_params,img_size):\n",
    "    \"\"\" Loads the trained model\n",
    "    args: \n",
    "    model_weights_filename (str): .h5 file containing the weights of the trained model.\n",
    "    loss_type (str): 'full' or 'diag', depending on the type of covariance matrix chosen\n",
    "    model type (str): 'xresnet34' or 'xresnet101', according to the choice of network\n",
    "    learning_params (list of str): Parameters learnt by the network\n",
    "    img_size (int): Dimensions of the input images\"\"\"\n",
    "    num_params = len(learning_params+log_learning_params)\n",
    "    if loss_type == 'full':\n",
    "        num_outputs = num_params + int(num_params*(num_params+1)/2)\n",
    "        loss_func = loss_functions.FullCovarianceLoss(num_params)\n",
    "    elif loss_type == 'diag':\n",
    "        num_outputs = 2*num_params\n",
    "        loss_func = loss_functions.DiagonalCovarianceLoss(num_params)\n",
    "    if model_type == 'xresnet101':\n",
    "        model = conv_models.build_xresnet101(img_size,num_outputs)\n",
    "    if model_type == 'xresnet34':\n",
    "        model = conv_models.build_xresnet34(img_size,num_outputs)\n",
    "    model.load_weights(model_weights_filename,by_name=True,skip_mismatch=True)\n",
    "    return model,loss_func,num_params\n",
    "\n",
    "#Import training configs\n",
    "from paltas.Analysis.AnalysisConfigs.train_config_examp_tutorial import learning_params,batch_size,flip_pairs,\\\n",
    "                                                               n_epochs,random_seed,norm_images,\\\n",
    "                                                               loss_function,model_type,\\\n",
    "                                                               npy_folders_train,img_size\n",
    "\n",
    "\n",
    "corner_param_print= [elem.replace('main_deflector_parameters_','').replace('subhalo_parameters_','')\\\n",
    "                     for elem in learning_params]\n",
    "\n",
    "model,loss_func,num_params = load_model(final_weights_filename,loss_function,learning_params=learning_params,\\\n",
    "                             log_learning_params=[],model_type=model_type,img_size=img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486bfe70-a67b-4273-ae2c-b57ebf79be5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Generate Network Predictions\n",
    "The network predictions are then loaded, for testing on the validation set generated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649580d4-d101-4350-b992-a98f2ef3565c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T01:23:43.307405Z",
     "start_time": "2023-08-21T01:23:43.283035Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_network_predictions(test_folder,norm_path,learning_params,log_learning_params,loss_type,\n",
    "                            loss_func,model,shuffle=True,\n",
    "                            norm_images=True,log_norm_images=False):\n",
    "    \"\"\"\n",
    "    Generate neural network predictions given a paltas generated folder of images\n",
    "\n",
    "    Args:\n",
    "        test_folder (string): Path to folder of paltas generated images, \n",
    "            containig a data.tfrecord file\n",
    "        norm_path (string): Path to .csv containing normalization of parameters\n",
    "            applied during training of network\n",
    "        learning_params (list(string)): Names of parameters learned\n",
    "        loss_type (string): 'full' or 'diag' currently supported\n",
    "        loss_func (paltas.Analysis.loss_function): Loss function object, (needs\n",
    "            draw_samples() and convert_output() functionality)\n",
    "        model (paltas.Analysis.conv_models): Trained neural network with weights\n",
    "            loaded\n",
    "        shuffle (bool, default=True): If True, the order of the test set is shuffled\n",
    "            when generating predictions\n",
    "        norm_images (bool, default=True): If True, normalize test set images\n",
    "        log_norm_images (bool, default=False): If True, test set imags are\n",
    "            log-normalized and rescaled to range (0,1)\n",
    "\n",
    "    Returns:\n",
    "        y_test, y_pred, std_pred, prec_pred\n",
    "    \"\"\"\n",
    "\n",
    "    tfr_test_path = os.path.join(test_folder,'data.tfrecord')\n",
    "    input_norm_path = norm_path\n",
    "\n",
    "    if loss_type not in {'full','diag'}:\n",
    "        raise ValueError('loss_type not supported')\n",
    "    tf_dataset_test = dataset_generation.generate_tf_dataset(tf_record_path = tfr_test_path,\\\n",
    "                                                             learning_params = learning_params,\n",
    "                                                             batch_size = 3,\\\n",
    "                                                             n_epochs = 1,\\\n",
    "                                                             norm_images=norm_images,\n",
    "                                                             kwargs_detector=None,\\\n",
    "                                                             input_norm_path=input_norm_path,\n",
    "                                                             log_learning_params=log_learning_params,\\\n",
    "                                                             shuffle=shuffle)\n",
    "\n",
    "    y_test_list = [];y_pred_list = []\n",
    "    std_pred_list = [];cov_pred_list = []\n",
    "    predict_samps_list = []\n",
    "\n",
    "    for batch in tf_dataset_test:\n",
    "        images = batch[0].numpy()\n",
    "        y_test = batch[1].numpy()\n",
    "        \n",
    "        # use unrotated output for covariance matrix\n",
    "        output = model.predict(images)\n",
    "\n",
    "        if loss_type == 'full':\n",
    "            y_pred, precision_matrix, _ = loss_func.convert_output(output)\n",
    "        else:\n",
    "            y_pred, log_var_pred = loss_func.convert_output(output)\n",
    "\n",
    "        # compute std. dev.\n",
    "        if loss_type == 'full':\n",
    "            cov_mat = np.linalg.inv(precision_matrix.numpy())\n",
    "            std_pred = np.zeros((cov_mat.shape[0],cov_mat.shape[1]))\n",
    "            for i in range(len(std_pred)):\n",
    "                std_pred[i] = np.sqrt(np.diag(cov_mat[i]))\n",
    "            \n",
    "        else:\n",
    "            std_pred = np.exp(log_var_pred/2)\n",
    "            cov_mat = np.empty((len(std_pred),len(std_pred[0]),len(std_pred[0])))\n",
    "            for i in range(len(std_pred)):\n",
    "                cov_mat[i] = np.diag(std_pred[i]**2)\n",
    "\n",
    "        y_test_list.append(y_test)\n",
    "        y_pred_list.append(y_pred)\n",
    "        std_pred_list.append(std_pred)\n",
    "        cov_pred_list.append(cov_mat)\n",
    "\n",
    "    y_test = np.concatenate(y_test_list)\n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    std_pred = np.concatenate(std_pred_list)\n",
    "    cov_pred = np.concatenate(cov_pred_list)\n",
    "\n",
    "    if input_norm_path is not None:\n",
    "        dataset_generation.unnormalize_outputs(input_norm_path,learning_params+log_learning_params,\n",
    "                                        y_pred,standard_dev=std_pred,cov_mat=cov_pred)\n",
    "        dataset_generation.unnormalize_outputs(input_norm_path,learning_params+log_learning_params,\n",
    "                                        y_test)\n",
    "    prec_pred = np.linalg.inv(cov_pred)\n",
    "   \n",
    "    return y_test, y_pred, std_pred, prec_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c7920e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T01:24:20.113218Z",
     "start_time": "2023-08-21T01:23:56.957000Z"
    }
   },
   "outputs": [],
   "source": [
    "network_predictions = gen_network_predictions(\\\n",
    "                        test_folder=training_directory+'/validation/1',\\\n",
    "                        norm_path=training_directory+'/training/1/norms.csv',\\\n",
    "                        learning_params=learning_params,\\\n",
    "                        log_learning_params = [],\\\n",
    "                        loss_type=loss_function,\n",
    "                        loss_func=loss_func,\\\n",
    "                        model=model,shuffle=True,\n",
    "                        norm_images=norm_images,log_norm_images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d10f5e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot Network Output Distributions\n",
    "We now plot the distributions of the network predictions, and compare those to the ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda9575c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T00:19:17.305895Z",
     "start_time": "2023-08-21T00:19:10.361558Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_kwargs = {'fontsize': 20}\n",
    "fig = pl.figure(figsize=(3*len(learning_params),3*len(learning_params)))\n",
    "corner.corner(network_predictions[0],fig=fig,color='k')\n",
    "corner.corner(network_predictions[1],fig=fig,color='red',\\\n",
    "              labels=corner_param_print,\\\n",
    "              label_kwargs=label_kwargs)\n",
    "pl.legend(['Truth','Pred'])\n",
    "pl.tight_layout()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69abca-7ed4-431b-adda-fe3bb2402030",
   "metadata": {},
   "source": [
    "## Load Model Outputs\n",
    "The hyperparameters of the training set are loaded (to use as an interim prior in the hierarchical inference), along with the network predictions for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d5996-53bc-45cd-a958-e12b338ec918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T00:45:41.682367Z",
     "start_time": "2023-08-21T00:45:41.663404Z"
    }
   },
   "outputs": [],
   "source": [
    "train_mean = np.array(pd.read_csv(training_directory+'/training/1/norms.csv')['mean']) \n",
    "train_scatter = np.array(pd.read_csv(training_directory+'/training/1/norms.csv')['std']) \n",
    "\n",
    "#Since we are using a diagonal covariance matrix, the precision matrix is the diagonal matrix of\n",
    "#the (elementwise) values of 1/std^2. In general however it is inv(cov_matrix).\n",
    "network_means = network_predictions[1][:,:].astype('float64')              \n",
    "network_prec = network_predictions[3][:,:,:].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1388d8f2-b579-4838-8c6b-22eefdc07818",
   "metadata": {},
   "source": [
    "# Hierarchical Inference\n",
    "The following performs hierarchical inference to retrieve the population hyperparameters of the validation set, assuming a diagonal covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf27b26-01fe-4691-90dd-5d88f7ba12b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T01:24:52.451507Z",
     "start_time": "2023-08-21T01:24:52.433580Z"
    }
   },
   "outputs": [],
   "source": [
    "def hierarchical_inference_func(n_lenses,y_pred,prec_pred,train_mean,train_scatter,n_param=None,n_samps = 1e+4):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        sampler object\n",
    "    \"\"\"\n",
    "    # Load the predictions for the mean and covariance for our model. We'll have to do a little reshaping here since the code\n",
    "    # expect an array of mean values and a precision matrix.\n",
    "    y_pred_hi = y_pred\n",
    "    prec_pred_hi = prec_pred\n",
    "    # The interim training distribution.\n",
    "    mu_omega_i = np.array(train_mean)\n",
    "    cov_omega_i = np.diag(np.array(train_scatter)**2)\n",
    "    if n_param is None: ndim =2*num_params\n",
    "    else: ndim = 2*n_param\n",
    "    # uniform prior with bounds\n",
    "    @numba.njit()\n",
    "    def eval_func_omega(hyperparameters):\n",
    "        # log prior for uniform in sigma space, as opposed to uniform in log space\n",
    "        return 0#np.sum(hyperparameters[int(ndim/2):])\n",
    "\n",
    "    # Initialize our class and then give it the network predictions. These are set to global variables in case you want to use\n",
    "    # pooling.\n",
    "    prob_class = hierarchical_inference.ProbabilityClassAnalytical(mu_omega_i,cov_omega_i,eval_func_omega)\n",
    "    prob_class.set_predictions(mu_pred_array_input=y_pred_hi,prec_pred_array_input=prec_pred_hi)\n",
    "\n",
    "    # Set a few of the parameters we will need to pass to emcee\n",
    "    n_walkers = 40\n",
    "    # Generate an initial state informed by prior range\n",
    "    cur_state_mu = np.concatenate([np.random.uniform(low=-5,high=5,size=(n_walkers,1))\\\n",
    "                                   for i in range(int(ndim/2))],axis=1)\n",
    "    cur_state_sigmas = np.log(np.concatenate([np.random.uniform(low=0.01,high=0.01,size=(n_walkers,1))\\\n",
    "                                   for i in range(int(ndim/2))],axis=1))\n",
    "    cur_state = np.concatenate((cur_state_mu,cur_state_sigmas),axis=1)\n",
    "    sampler = emcee.EnsembleSampler(n_walkers, ndim,prob_class.log_post_omega)\n",
    "    _ = sampler.run_mcmc(cur_state,n_samps,progress=True,skip_initial_state_check=True)\n",
    " \n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6625df-1c23-4815-8765-d5f1ea9e6340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T02:58:16.584101Z",
     "start_time": "2023-08-21T01:25:04.814238Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "burnin = int(10)\n",
    "\n",
    "sampler = hierarchical_inference_func(1000,network_means,network_prec,\\\n",
    "                      train_mean[:].astype('float64'),train_scatter[:].astype('float64'),n_samps=100)\n",
    "chain = sampler.chain[:,burnin:,:].reshape((-1,2*num_params))[:,0:num_params] #Just using the means for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee64d8-1ef0-45f5-8236-45b847d4b87b",
   "metadata": {},
   "source": [
    "# Results\n",
    "We plot the results of the hierarchical inference here: the ground-truth is plotted as solid black lines, along with the population posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787341a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T03:15:54.173143Z",
     "start_time": "2023-08-21T03:15:48.438905Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels_kwargs = {'fontsize':20}\n",
    "hist_kwargs = {'density':True,'color':'orange','lw':3}\n",
    "fig = pl.figure(figsize=(3*len(learning_params),3*len(learning_params)))\n",
    "corner.corner(chain,labels=[f'$\\mu_{elem}$' for elem in corner_param_print],fig=fig,show_titles=False,plot_datapoints=False,\\\n",
    "              label_kwargs=labels_kwargs,\\\n",
    "              levels=[0.68,0.95],color='orange',fill_contours=True,hist_kwargs=hist_kwargs,title_fmt='.2f',\\\n",
    "              truths=[1.1,0,0,2,0,0,0,0],truth_color='k',\\\n",
    "              max_n_ticks=3,bins=20)\n",
    "\n",
    "pl.tight_layout()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c484cc85",
   "metadata": {},
   "source": [
    "# Endnote\n",
    "We have now 1) generated simulated lensed images, 2) trained a neural network to model these images, 3) applied the trained network to a different set of images and 4) run hierarchical inference to infer population-level parameters.\\\n",
    "You may note that the final results could be improved - the configuration settings used here were chosen for speed rather than precision. For science-level results, the following should be changed:\n",
    "1) Increase the training-set size for the neural network,\n",
    "2) Increase the number of epochs the network trains for,\n",
    "3) Increase the number of iterations (and burn-in) of the MCMC used for hierarchical inference.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "685px",
    "left": "28px",
    "top": "359px",
    "width": "305.74px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
