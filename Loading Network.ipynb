{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09a55266-f83e-4df6-bd48-9ed741cdb5a9",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6254537e-c74f-432f-949f-f7532525afc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 15:42:04.126973: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numba/core/decorators.py:262: NumbaDeprecationWarning: numba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.chdir('/Users/hollowayp/paltas')\n",
    "from paltas.Analysis import dataset_generation, loss_functions, conv_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49e51c-4d24-4569-b30e-fb9d84333898",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9cf97e9-1fc8-47f5-bd3a-2b87e5610c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = '/Users/hollowayp/paltas/paltas/example_network_weights/path_to_model_weights_200-5566125.00.h5'\n",
    "EPOCH = 200\n",
    "img_size = (160,160,1)\n",
    "random_seed = 2\n",
    "batch_size = 5\n",
    "flip_pairs = None\n",
    "NORM_IMAGES = True\n",
    "LOG_NORM_IMAGES = False\n",
    "learning_params = ['main_deflector_parameters_theta_E',\n",
    "                    'main_deflector_parameters_gamma1','main_deflector_parameters_gamma2',\n",
    "                    'main_deflector_parameters_gamma','main_deflector_parameters_e1',\n",
    "                    'main_deflector_parameters_e2','main_deflector_parameters_center_x',\n",
    "                    'main_deflector_parameters_center_y',\n",
    "                    'subhalo_parameters_sigma_sub']\n",
    "learning_params_print = [r'$\\theta_\\mathrm{E}$',r'$\\gamma_1$',r'$\\gamma_2$',r'$\\gamma_\\mathrm{lens}$',r'$e_1$',\n",
    "                         r'$e_2$',r'$x_\\mathrm{lens}$',r'$y_\\mathrm{lens}$']\n",
    "                         #r'x_{\\mathrm{src}}',r'y_{\\mathrm{src}}',r'R_{src}']\n",
    "log_learning_params = []\n",
    "num_params = len(learning_params+log_learning_params)\n",
    "loss_type = 'full'\n",
    "model_type = 'xresnet34'\n",
    "\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "if loss_type == 'full':\n",
    "    num_outputs = num_params + int(num_params*(num_params+1)/2)\n",
    "    loss_func = loss_functions.FullCovarianceLoss(num_params)\n",
    "\n",
    "elif loss_type == 'diag':\n",
    "    num_outputs = 2*num_params\n",
    "    loss_func = loss_functions.DiagonalCovarianceLoss(num_params)\n",
    "\n",
    "if model_type == 'xresnet101':\n",
    "    model = conv_models.build_xresnet101(img_size,num_outputs)\n",
    "if model_type == 'xresnet34':\n",
    "    model = conv_models.build_xresnet34(img_size,num_outputs)\n",
    "model.load_weights(model_weights)\n",
    "#model.load_weights(model_weights,by_name=True,skip_mismatch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c16b2c5-a5eb-44f0-a89a-9973ddf3360f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x13d1699c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c13fc-c3f1-4d6c-8d87-da5e49fce37a",
   "metadata": {},
   "source": [
    "### Make Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15059de5-f614-48f8-81cd-a7f3d09117df",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1235189569.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 42\u001b[0;36m\u001b[0m\n\u001b[0;31m    Print table of metrics in latex format\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "file_prefix = '../../STRIDES14results/july13_src_info/'\n",
    "validation_prefix = '../../STRIDES14results/may22_2023/'\n",
    "already_computed = False\n",
    "\n",
    "\n",
    "if already_computed:\n",
    "    y_test = np.load(file_prefix+'val'+str(EPOCH)+'_y_test.npy')\n",
    "    y_pred = np.load(file_prefix+'val'+str(EPOCH)+'_y_pred.npy')\n",
    "    std_pred = np.load(file_prefix+'val'+str(EPOCH)+'_std_pred.npy')\n",
    "    predict_samps = np.load(file_prefix+'val'+str(EPOCH)+'_predict_samps.npy')\n",
    "    prec_pred = np.load(file_prefix+'val'+str(EPOCH)+'_prec_pred.npy')\n",
    "\n",
    "else:\n",
    "    npy_folder_test = validation_prefix + 'validate/'\n",
    "    tfr_test_path = os.path.join(npy_folder_test,'data.tfrecord')\n",
    "    input_norm_path = file_prefix+'norms_5e-4_1e3.csv'\n",
    "\n",
    "    y_test, y_pred, std_pred, prec_pred, predict_samps = mcmc_utils.gen_network_predictions(npy_folder_test,\n",
    "        input_norm_path,learning_params,loss_func,model,samples=True,shuffle=False,\n",
    "        norm_images=NORM_IMAGES,log_norm_images=LOG_NORM_IMAGES)\n",
    "    \n",
    "    np.save(file_prefix+'val'+str(EPOCH)+'_y_test.npy',y_test)\n",
    "    np.save(file_prefix+'val'+str(EPOCH)+'_y_pred.npy',y_pred)\n",
    "    np.save(file_prefix+'val'+str(EPOCH)+'_std_pred.npy',std_pred)\n",
    "    np.save(file_prefix+'val'+str(EPOCH)+'_predict_samps.npy',predict_samps)\n",
    "    np.save(file_prefix+'val'+str(EPOCH)+'_prec_pred.npy',prec_pred)\n",
    "df = pd.read_csv('../../STRIDES14results/may22_2023/validate/metadata.csv')\n",
    "plt.hist(df['point_source_parameters_num_images'].to_numpy())\n",
    "plt.title(\"Num PS Images in Validation Set\")\n",
    "num_images = df['point_source_parameters_num_images'].to_numpy()\n",
    "np.sum(num_images == 5) / np.size(num_images)\n",
    "#print(np.where(num_images == 3)[0])\n",
    "\n",
    "#df['point_source_parameters_x_image_2'].to_numpy()[30]\n",
    "# find a way to exclude 3 / 5 image configurations (they most likely come from numerical limitations of lenstronomy)\n",
    "# probably should train on quads only, find a way to evaluate P(xi_k|Omega_int) numerically like Sherry suggested...\n",
    "    # you have a histogram of probably density from 500,000 images, bin it very finely\n",
    "    # given a value, assign it to a bin, and then ask for what probably density that bin has \n",
    "    # this is an approximate way to evaluate the p(xi_k|Omega_int) without assigning a functional form...\n",
    "    # this also motivates the move to jax to make things faster (sampling not analytical)\n",
    "    # is jax / numpyro working on sherlock?\n",
    "Print table of metrics in latex format\n",
    "\n",
    "file_prefix = '../../STRIDES14results/may22_2023/'\n",
    "# indices of interest\n",
    "iofi = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "visualization_utils.table_metrics(y_pred[:,iofi],y_test[:,iofi],std_pred[:,iofi],\n",
    "    file_prefix+'validation_set.txt')\n",
    "f = open(file_prefix+'validation_set.txt', 'r')\n",
    "file_contents = f.read()\n",
    "print(file_contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
